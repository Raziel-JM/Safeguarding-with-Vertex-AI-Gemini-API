
# ğŸ›¡ï¸ Safeguarding with Vertex AI Gemini API

Este repositorio contiene el notebook `gemini_safety_ratings.ipynb`, el cual explora el uso de **Vertex AI Gemini API** para evaluar la seguridad de modelos de IA.

## ğŸ“Œ DescripciÃ³n
El propÃ³sito de este proyecto es demostrar cÃ³mo implementar evaluaciones de seguridad en modelos de IA utilizando Google Vertex AI y prÃ¡cticas de IA responsable.

## ğŸ› ï¸ TecnologÃ­as utilizadas
- Google Cloud Platform (GCP)
- Vertex AI
- Python (Pandas, NumPy)
- Jupyter Notebook

## ğŸ“‚ Estructura del repositorio
```
/Safeguarding-with-Vertex-AI-Gemini-API
â”‚â”€â”€ gemini_safety_ratings.ipynb  # Notebook con la implementaciÃ³n
â”‚â”€â”€ README.md                     # DocumentaciÃ³n del proyecto
```

## ğŸš€ CÃ³mo ejecutar el notebook

### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/Raziel-JM/Safeguarding-with-Vertex-AI-Gemini-API.git
cd Safeguarding-with-Vertex-AI-Gemini-API
```

### 2ï¸âƒ£ Instalar dependencias (opcional)
Si el notebook requiere paquetes especÃ­ficos, instÃ¡lalos con:
```bash
pip install -r requirements.txt  # Si hay un archivo con dependencias
```

### 3ï¸âƒ£ Ejecutar Jupyter Notebook
```bash
jupyter notebook
```

## ğŸ“– Recursos adicionales
- [ğŸ“„ DocumentaciÃ³n de Vertex AI](https://cloud.google.com/vertex-ai/docs)
- [ğŸ›¡ï¸ GuÃ­a de IA Responsable](https://ai.google/responsibility/)

## ğŸ“œ Licencia
Este proyecto estÃ¡ bajo la licencia **MIT**.

---
