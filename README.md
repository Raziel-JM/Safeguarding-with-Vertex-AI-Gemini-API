
# 🛡️ Safeguarding with Vertex AI Gemini API

Este repositorio contiene el notebook `gemini_safety_ratings.ipynb`, el cual explora el uso de **Vertex AI Gemini API** para evaluar la seguridad de modelos de IA.

## 📌 Descripción
El propósito de este proyecto es demostrar cómo implementar evaluaciones de seguridad en modelos de IA utilizando Google Vertex AI y prácticas de IA responsable.

## 🛠️ Tecnologías utilizadas
- Google Cloud Platform (GCP)
- Vertex AI
- Python (Pandas, NumPy)
- Jupyter Notebook

## 📂 Estructura del repositorio
```
/Safeguarding-with-Vertex-AI-Gemini-API
│── gemini_safety_ratings.ipynb  # Notebook con la implementación
│── README.md                     # Documentación del proyecto
```

## 🚀 Cómo ejecutar el notebook

### 1️⃣ Clonar el repositorio
```bash
git clone https://github.com/Raziel-JM/Safeguarding-with-Vertex-AI-Gemini-API.git
cd Safeguarding-with-Vertex-AI-Gemini-API
```

### 2️⃣ Instalar dependencias (opcional)
Si el notebook requiere paquetes específicos, instálalos con:
```bash
pip install -r requirements.txt  # Si hay un archivo con dependencias
```

### 3️⃣ Ejecutar Jupyter Notebook
```bash
jupyter notebook
```

## 📖 Recursos adicionales
- [📄 Documentación de Vertex AI](https://cloud.google.com/vertex-ai/docs)
- [🛡️ Guía de IA Responsable](https://ai.google/responsibility/)

## 📜 Licencia
Este proyecto está bajo la licencia **MIT**.

---
